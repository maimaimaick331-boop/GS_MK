"""
æ•°æ®åº“ç®¡ç†å·¥å…·
ç”¨äºç®¡ç†å’Œç»´æŠ¤SQLiteæ•°æ®åº“
"""

import sqlite3
import os
from datetime import datetime, timedelta
import argparse

DB_PATH = 'data/silver_gold.db'

def get_db():
    """è·å–æ•°æ®åº“è¿æ¥"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn

def backup_database():
    """å¤‡ä»½æ•°æ®åº“"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_path = f'data/backup/silver_gold_{timestamp}.db'
    
    # åˆ›å»ºå¤‡ä»½ç›®å½•
    os.makedirs('data/backup', exist_ok=True)
    
    conn = get_db()
    backup_conn = sqlite3.connect(backup_path)
    conn.backup(backup_conn)
    backup_conn.close()
    conn.close()
    
    print(f"âœ“ æ•°æ®åº“å¤‡ä»½å®Œæˆ: {backup_path}")

def cleanup_old_logs(days=90):
    """æ¸…ç†æ—§æ—¥å¿—"""
    conn = get_db()
    cursor = conn.cursor()
    
    cutoff_date = datetime.now() - timedelta(days=days)
    
    cursor.execute(
        "DELETE FROM data_log WHERE created_at < ?",
        (cutoff_date.isoformat(),)
    )
    
    deleted = cursor.rowcount
    conn.commit()
    conn.close()
    
    print(f"âœ“ å·²åˆ é™¤ {deleted} æ¡æ—§æ—¥å¿—è®°å½• (è¶…è¿‡ {days} å¤©)")

def cleanup_old_data(days=365):
    """æ¸…ç†æ—§æ•°æ®"""
    conn = get_db()
    cursor = conn.cursor()
    
    cutoff_date = datetime.now() - timedelta(days=days)
    
    tables = [
        'comex_warehouse',
        'silver_etf',
        'silver_price',
        'gold_data'
    ]
    
    total_deleted = 0
    for table in tables:
        cursor.execute(
            f"DELETE FROM {table} WHERE created_at < ?",
            (cutoff_date.isoformat(),)
        )
        total_deleted += cursor.rowcount
        print(f"  {table}: åˆ é™¤ {cursor.rowcount} æ¡è®°å½•")
    
    conn.commit()
    conn.close()
    
    print(f"âœ“ å·²åˆ é™¤æ€»å…± {total_deleted} æ¡æ—§æ•°æ® (è¶…è¿‡ {days} å¤©)")

def get_statistics():
    """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
    conn = get_db()
    cursor = conn.cursor()
    
    print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
    print("=" * 50)
    
    tables = [
        ('comex_warehouse', 'COMEXåº“å­˜è®°å½•'),
        ('silver_etf', 'ETFæŒä»“è®°å½•'),
        ('silver_price', 'ä»·æ ¼è®°å½•'),
        ('gold_data', 'åˆ†ææ•°æ®è®°å½•'),
        ('data_log', 'é‡‡é›†æ—¥å¿—')
    ]
    
    for table, label in tables:
        cursor.execute(f"SELECT COUNT(*) as count FROM {table}")
        count = cursor.fetchone()['count']
        
        # è·å–æœ€æ–°å’Œæœ€æ—§çš„è®°å½•æ—¶é—´
        cursor.execute(f"SELECT MIN(created_at) as oldest FROM {table}")
        oldest = cursor.fetchone()['oldest']
        
        cursor.execute(f"SELECT MAX(created_at) as newest FROM {table}")
        newest = cursor.fetchone()['newest']
        
        print(f"\n{label}:")
        print(f"  æ€»è®°å½•æ•°: {count}")
        if oldest:
            print(f"  æœ€æ—§è®°å½•: {oldest}")
        if newest:
            print(f"  æœ€æ–°è®°å½•: {newest}")
    
    # æ•°æ®åº“æ–‡ä»¶å¤§å°
    size = os.path.getsize(DB_PATH) / 1024 / 1024  # MB
    print(f"\nğŸ’¾ æ•°æ®åº“æ–‡ä»¶å¤§å°: {size:.2f} MB")
    
    conn.close()

def optimize_database():
    """ä¼˜åŒ–æ•°æ®åº“"""
    conn = get_db()
    cursor = conn.cursor()
    
    print("ä¼˜åŒ–æ•°æ®åº“ä¸­...")
    
    # æ¸…ç†ç¢ç‰‡
    cursor.execute("VACUUM")
    
    # åˆ†æè¡¨ä»¥ä¼˜åŒ–æŸ¥è¯¢
    cursor.execute("ANALYZE")
    
    # åˆ›å»ºç´¢å¼•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    indexes = [
        "CREATE INDEX IF NOT EXISTS idx_comex_date ON comex_warehouse(date)",
        "CREATE INDEX IF NOT EXISTS idx_etf_date ON silver_etf(date)",
        "CREATE INDEX IF NOT EXISTS idx_etf_name ON silver_etf(etf_name)",
        "CREATE INDEX IF NOT EXISTS idx_price_market ON silver_price(market)",
        "CREATE INDEX IF NOT EXISTS idx_price_date ON silver_price(date)",
        "CREATE INDEX IF NOT EXISTS idx_gold_category ON gold_data(category)",
        "CREATE INDEX IF NOT EXISTS idx_log_date ON data_log(created_at)",
    ]
    
    for idx in indexes:
        cursor.execute(idx)
    
    conn.commit()
    conn.close()
    
    print("âœ“ æ•°æ®åº“ä¼˜åŒ–å®Œæˆ")

def export_to_csv(table):
    """å¯¼å‡ºè¡¨æ•°æ®ä¸ºCSV"""
    import csv
    
    conn = get_db()
    cursor = conn.cursor()
    
    cursor.execute(f"SELECT * FROM {table}")
    columns = [description[0] for description in cursor.description]
    rows = cursor.fetchall()
    
    filename = f"export_{table}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    
    with open(filename, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(columns)
        for row in rows:
            writer.writerow(row)
    
    print(f"âœ“ å·²å¯¼å‡º {len(rows)} æ¡è®°å½•åˆ° {filename}")
    conn.close()

def main():
    parser = argparse.ArgumentParser(description='æ•°æ®åº“ç®¡ç†å·¥å…·')
    subparsers = parser.add_subparsers(dest='command')
    
    # å¤‡ä»½å‘½ä»¤
    subparsers.add_parser('backup', help='å¤‡ä»½æ•°æ®åº“')
    
    # æ¸…ç†æ—§æ—¥å¿—
    cleanup_logs = subparsers.add_parser('cleanup-logs', help='æ¸…ç†æ—§æ—¥å¿—')
    cleanup_logs.add_argument('--days', type=int, default=90, help='æ¸…ç†å¤šå°‘å¤©å‰çš„æ—¥å¿—')
    
    # æ¸…ç†æ—§æ•°æ®
    cleanup_data = subparsers.add_parser('cleanup-data', help='æ¸…ç†æ—§æ•°æ®')
    cleanup_data.add_argument('--days', type=int, default=365, help='æ¸…ç†å¤šå°‘å¤©å‰çš„æ•°æ®')
    
    # ç»Ÿè®¡ä¿¡æ¯
    subparsers.add_parser('stats', help='æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯')
    
    # ä¼˜åŒ–æ•°æ®åº“
    subparsers.add_parser('optimize', help='ä¼˜åŒ–æ•°æ®åº“')
    
    # å¯¼å‡ºæ•°æ®
    export = subparsers.add_parser('export', help='å¯¼å‡ºè¡¨æ•°æ®ä¸ºCSV')
    export.add_argument('table', help='è¡¨å')
    
    args = parser.parse_args()
    
    if args.command == 'backup':
        backup_database()
    elif args.command == 'cleanup-logs':
        cleanup_old_logs(args.days)
    elif args.command == 'cleanup-data':
        cleanup_old_data(args.days)
    elif args.command == 'stats':
        get_statistics()
    elif args.command == 'optimize':
        optimize_database()
    elif args.command == 'export':
        export_to_csv(args.table)
    else:
        parser.print_help()

if __name__ == '__main__':
    main()
